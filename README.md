# Analytics Portfolio

## [Project 1: Munchys Supply Chain](https://public.tableau.com/views/MunchysSalesInsight/MunchysPetSupplyExecutiveDashboard)

![Munchys Pet Supply Executive Dashboard](https://github.com/user-attachments/assets/ba7c6cef-b631-40f1-9e0b-74b861ccf74f)

* **Objective:** Develop an executive dashboard to monitor and analyze sales performance of Munchy’s Pet Supply.

* **Goal:** Provide key insights on revenue, product performance, customer segments, and regional sales to support data-driven decisions.

* **Dataset:** Sales transaction data including product categories, customer types, payment methods, regions, and sales metrics.

* **Key Analysis:**
  - Sales performance by region and customer segment
  - Top-performing products and categories
  - Revenue trends over time
  - Payment method distribution and impact

* **Tools Used:**
  - **Excel** – Data cleaning, preprocessing, and initial exploration
  - **PostgreSQL** – Data storage, querying, and transformation using SQL
  - **Tableau** – Data visualization and creation of interactive dashboards

* **Outcome:** Interactive dashboard enabling stakeholders to quickly assess sales trends, identify growth opportunities, and optimize business strategies.

## [Project 2: DataSearch Job Trends](https://public.tableau.com/views/3_5_final_dashboard_solution_17482520907860/JobAnalytics)

![Job Analytics](https://github.com/user-attachments/assets/9a369d50-c163-4334-b1dc-511d635df640)

* **Objective:** Develop a job market analytics dashboard to analyze job demand and hiring trends.
* **Goal:** Provide insights into job availability, industry demand, required skills, and job distribution to support career planning and workforce analysis.
* **Dataset:** Job listing data including job titles, industries, required skills, company names, locations, and posting counts.
* **Key Analysis:**
  - Top industries with the highest job demand
  - Most in-demand job roles and skills
  - Job distribution by location
  - Company-wise job posting analysis
* **Tools Used:**
  - **Excel** – Data cleaning and preparation
  - **PostgreSQL** – Data storage, querying, and transformation using SQL
  - **Tableau Public** – Interactive dashboard development and visualization
    
* **Outcome:** A dynamic dashboard that helps users understand job market trends, identify high-demand skills, and explore job opportunities across industries and locations.

## [Project 3: Just In Time Supply Chain](https://public.tableau.com/views/JustinTimeSupplyChainFindings/SupplyChain)

![Supply Chain](https://github.com/user-attachments/assets/f8ce7486-17a6-4996-ad03-44ea87460cfe)

* **Objective:** Create a supply chain dashboard to analyze operational efficiency and logistics performance for JustinTime Supply Chain.

* **Goal:** Provide actionable insights on inventory management, supplier performance, delivery efficiency, and order fulfillment to optimize supply chain operations.

* **Dataset:** Supply chain data including order details, product categories, supplier performance, shipping status, delivery times, and fulfillment rates.

* **Key Analysis:**
  - Inventory levels and stock movement
  - On-time delivery rates and shipping performance
  - Supplier reliability and performance
  - Order fulfillment rates and bottleneck identification

* **Tools Used:**
  - **Excel** – Data cleaning and preparation
  - **PostgreSQL** – Data storage, SQL querying, and transformation
  - **Tableau Public** – Interactive dashboard creation and data visualization

* **Outcome:** A dynamic dashboard that helps stakeholders monitor supply chain health, improve delivery performance, optimize inventory, and enhance supplier management.

## [Project 4: Just In Time Shipment](https://public.tableau.com/views/JustinTimeShipmentDashboard/Shipmentdashboard)

![Shipment dashboard](https://github.com/user-attachments/assets/b4fd4c3f-8cbd-4e40-b370-52ae63935870)

* **Objective:** Develop a shipment dashboard to track delivery performance and shipping efficiency for JustinTime.

* **Goal:** Provide insights into shipment status, delivery timelines, shipping delays, and carrier performance to optimize logistics operations.

* **Dataset:** Shipment data including order IDs, shipping dates, delivery dates, shipment status, carrier details, and delivery performance metrics.

* **Key Analysis:**
  - On-time vs delayed shipments
  - Delivery status breakdown (on-time, late, in transit)
  - Carrier performance analysis
  - Shipment trends over time and delivery efficiency

* **Tools Used:**
  - **Excel** – Data cleaning and preparation
  - **PostgreSQL** – Data storage, SQL querying, and data transformation
  - **Tableau Public** – Dashboard creation and data visualization

* **Outcome:** A dynamic dashboard that enables stakeholders to monitor shipment performance, identify delivery issues, improve carrier management, and streamline logistics processes.

## [Project 5: Just In Time Inventory](https://public.tableau.com/views/JustinTimeInventoryDashboard/Inventorydashboard)

![Inventory dashboard](https://github.com/user-attachments/assets/5fd64a03-4d31-4917-88c0-60db4057adab)

* **Objective:** Create an inventory dashboard to monitor stock levels, product movement, and warehouse efficiency for JustinTime.

* **Goal:** Provide insights into inventory management, stock availability, turnover rates, and restocking needs to optimize supply chain operations.

* **Dataset:** Inventory data including product IDs, categories, stock levels, warehouse locations, reorder points, and stock movement history.

* **Key Analysis:**
  - Current stock levels by product and warehouse
  - Fast-moving vs slow-moving products
  - Inventory turnover rate analysis
  - Restock alerts and stockout identification

* **Tools Used:**
  * **Excel** – Data cleaning and preparation
  * **PostgreSQL** – Data storage, SQL querying, and data transformation
  * **Tableau Public** – Dashboard creation and data visualization

* **Outcome:** An interactive dashboard that helps stakeholders track stock levels, manage inventory efficiently, prevent stockouts, and optimize warehouse operations.

## [Project 6: Atlas Labs HR Dashboard](https://public.tableau.com/views/AtlasLabsHRDashboard_17486115293760/HRDashboard)

![HR Dashboard](https://github.com/user-attachments/assets/229504dd-de89-4b71-995f-9dcc257fe5ff)

* **Objective:** Develop an HR dashboard to monitor workforce metrics and analyze employee-related data for Atlas Labs.

* **Goal:** Provide insights into employee demographics, turnover, hiring trends, and workforce distribution to support HR decision-making.

* **Dataset:** HR data including employee IDs, demographics, departments, job roles, tenure, hiring status, and attrition records.

* **Key Analysis:**
  - Employee distribution by department, role, and gender
  - Attrition rate analysis by department and job role
  - Hiring vs attrition trends over time
  - Workforce diversity and tenure distribution

* **Tools Used:**
  - **Excel** – Data cleaning and preparation
  - **PostgreSQL** – Data storage, SQL querying, and transformation
  - **Tableau Public** – Dashboard creation and data visualization

* **Outcome:** An interactive dashboard that helps HR teams monitor workforce trends, analyze attrition, track hiring needs, and support diversity and retention strategies.

## [Project 7: Databel Customer Churn](https://public.tableau.com/views/DatabelCustomerChurnDashboard_17481814276300/ChurnAnalysis)

![Churn Analysis](https://github.com/user-attachments/assets/5740d90f-20e3-40dd-acfe-d54b7d1ece95)

* **Objective:** Build a customer churn analysis dashboard to monitor customer retention and churn patterns for Databel.

* **Goal:** Provide insights into churn rates, customer behavior, and key factors influencing churn to support retention strategies.

* **Dataset:** Customer data including demographics, tenure, contract types, payment methods, service usage, and churn status.

* **Key Analysis:**
  - Churn rate by customer segment and contract type
  - Identification of key churn drivers (e.g., tenure, payment methods)
  - Customer distribution by churn status
  - Trends in active vs churned customers over time

* **Tools Used:**
  - **Excel** – Data cleaning and preparation
  - **PostgreSQL** – Data storage, SQL querying, and data transformation
  - **Tableau Public** – Dashboard creation and data visualization

* **Outcome:** An interactive dashboard that helps businesses understand churn patterns, identify at-risk customers, and implement data-driven customer retention strategies.

## [Project 8: Inventory Analysis for Acropolis Retail Ltd.](https://public.tableau.com/views/InventoryAnalysisStory/InventoryAnalysis)

![Inventory Analysis](https://github.com/user-attachments/assets/c0ba1af4-cdbc-48f1-acb6-05826fae6125)

* **Objective:** Build an inventory analysis dashboard to track stock levels, product movement, and inventory performance.

* **Goal:** Provide insights into inventory health, stock availability, turnover rates, and replenishment needs to improve operational efficiency.

* **Dataset:** Inventory data including product IDs, categories, stock levels, sales data, reorder points, and warehouse locations.

* **Key Analysis:**
  - Stock levels by product and warehouse
  - Fast-moving vs slow-moving items
  - Inventory turnover rate and stock aging
  - Restocking needs and stockout risk identification

* **Tools Used:**
  - **Excel** – Data cleaning and preprocessing
  - **PostgreSQL** – Data storage, SQL querying, and data transformation
  - **Tableau Public** – Interactive dashboard creation and data visualization

* **Outcome:** A dynamic dashboard that enables stakeholders to monitor inventory status, optimize stock management, reduce stockouts, and improve supply chain efficiency.

## [Project 9: Divvy Historical Trip](https://public.tableau.com/views/DivvyHistoricalTrip/Whoaretheriders)

![Who are the riders_](https://github.com/user-attachments/assets/27d46abf-1f95-471d-944a-38dfab848794)

* **Objective:** Develop a trip analysis dashboard to understand rider behavior and usage patterns for Divvy Bike Sharing.

* **Goal:** Provide insights into rider demographics, trip patterns, and differences between casual and member riders to support business strategies.

* **Dataset:** Divvy historical trip data including rider types, trip durations, start/end stations, rideable types, and trip dates.

* **Key Analysis:**
  - Rider segmentation: casual vs member riders
  - Trip duration and frequency analysis
  - Popular routes and stations
  - Ride patterns by day, month, and bike type

* **Tools Used:**
  - **Excel** – Data cleaning and preprocessing
  - **PostgreSQL** – Data storage, SQL querying, and transformation
  - **Tableau Public** – Interactive dashboard creation and data visualization

* **Outcome:** An interactive dashboard that helps stakeholders understand rider behavior, optimize bike distribution, improve service offerings, and enhance user experience.

## [Project 10: HealthStat Length of Stay (LOS) Comparison](https://public.tableau.com/views/HealthStatLOSComparison/LOSdashboard)

![LOS dashboard](https://github.com/user-attachments/assets/6c9b820f-1366-4451-bbb6-8480186cb829)

* **Objective:** Create a Length of Stay (LOS) dashboard to analyze patient stay duration and hospital performance.

* **Goal:** Provide insights into average LOS, patient flow, and departmental efficiency to support healthcare management and operational improvements.

* **Dataset:** Hospital data including patient IDs, admission/discharge dates, departments, diagnoses, and length of stay records.

* **Key Analysis:**
  - Average LOS by department and diagnosis
  - LOS comparison across departments
  - Patient admission and discharge trends
  - Identification of departments with high or low LOS

* **Tools Used:**
  - **Excel** – Data cleaning and preprocessing
  - **PostgreSQL** – Data storage, SQL querying, and data transformation
  - **Tableau Public** – Dashboard development and data visualization

* **Outcome:** An interactive dashboard that enables healthcare providers to monitor patient LOS, optimize resource allocation, improve patient flow, and enhance operational efficiency.

## [Project 11: Analyzing Unicorn Companies](https://firdausdimmas.github.io/SQLProject_1/)

* **Objective:** Support an investment firm in analyzing high-growth company trends.
* **Goal:** Identify top-performing industries by company valuation and track the emergence rate of high-value companies.
* **Dataset:** Company information, valuations, industry classifications, and founding years.
* **Key Analysis**: Identified top unicorn-producing industries (2019-2021), peak year for new unicorns, and average valuation differences across industries.
* **Tools:** SQL (PostgreSQL), with data querying, aggregation, and trend analysis techniques.
* **Outcome:** Deliver insights to guide portfolio optimization and strategic investment decisions based on industry growth patterns.

## [Project 12: Evaluate a Manufacturing Process](https://firdausdimmas.github.io/SQLProject_2/)

* **Objective:** Enhance manufacturing quality through Statistical Process Control (SPC).
* **Goal:** Identify and minimize defects by establishing control limits and analyzing production data.
* **Dataset:** `manufacturing_parts` table, containing `item_no`, `length`, `width`, `height`, and `operator` data.
* **Key Analysis:** Calculated Upper/Lower Control Limits (UCL/LCL) for product height; identified out-of-control parts and operator performance.
* **Tools used:** SQL (PostgreSQL) for data analysis and SPC calculations.
* **Outcome:** Found 57 out of 363 parts out of control, with Operator 5 having the most alerts, leading to recommendations for root cause analysis and training.

## [Project 13: Analyzing Motorcycle Part Sales](https://firdausdimmas.github.io/SQLProject_3/)

* **Objective:** Analyze motorcycle part sales data to understand wholesale revenue by product line, month, and warehouse.
* **Goal:** Calculate net wholesale revenue for each product line, categorized by month and warehouse.
* **Dataset:** `sales` table, including `order_number`, `date`, `warehouse`, `client_type`, `product_line`, `quantity`, `unit_price`, `total`, `payment`, and `payment_fee`, covering June-August 2021 orders.
* **Key Analysis:** Determined top-earning wholesale product lines, compared revenue across three warehouses (North, Central, West), and identified monthly revenue trends.
* **Tools used:** SQL (PostgreSQL) for querying and aggregating sales data.
* **Outcome:** Engine Parts and Frame & Body were top revenue generators; Central Warehouse led in revenue; and revenue showed a strong upward trend from June to August.

## [Project 14: Impact Analysis of GoodThought NGO Initiatives](https://firdausdimmas.github.io/SQLProject_4/)

* **Objective:** Optimize GoodThought NGO's impact and resource allocation using data from their PostgreSQL database (2010-2023).
* **Goal:** Analyze trends, evaluate program effectiveness, and identify improvement opportunities for the NGO.
* **Dataset:** GoodThought's PostgreSQL database, containing `Assignments`, `Donations`, and `Donors` tables (2010-2023).
* **Key Analysis:** Identifying top-funded assignments, donor contributions by region/category, and high-impact assignments across regions.
* **Tools used:** SQL (PostgreSQL) for trend analysis.
* **Outcome:** Identified top-funded assignments, regional donor patterns, and high-impact assignments.

## [Project 15: Impact Analysis of GoodThought NGO Initiatives](https://firdausdimmas.github.io/SQLProject_5/)

* **Objective:** Explore factors influencing student success through analyzing lifestyle habits and exam performance.
* **Goal:** Uncover relationships between student habits and academic performance for educational improvement.
* **Dataset:** `student_performance`.
* **Key Analysis:** Examined correlations between study hours, extracurriculars, sleep duration, and exam scores/ranks.
* **Tools used:** SQL (PostgreSQL) for enabling the analysis of factors influencing student success.
* **Outcome:** Found positive links between increased study/extracurriculars and scores, optimal study hours (11-15 hrs), and balanced sleep (6-8 hrs) among top performers.

## [Project 16: Analyze International Debt Statistics](https://firdausdimmas.github.io/SQLProject_6/)

* **Objective:** Uncover key insights into the debt situation of developing nations, including identifying major debtors, debt distribution, and overall trends.
* **Goal:** Provide a clearer understanding of how debt supports economic development and offer valuable insights for stakeholders and policymakers.
* **Dataset:** International debt data collected by The World Bank.
* **Key Analysis:** Analyzed international debt data to identify the largest debtors, understand debt distribution, and recognize overall debt trends among 124 developing countries.
* **Tools used:** PostgreSQL was used to store and manage The World Bank's international debt data for analysis and querying.
* **Outcome:** Identified 124 distinct developing countries in the dataset, with China having the highest total debt (approx. \$285 billion USD) and Timor Leste having the lowest principal repayments (as low as \$825,000 USD).

## [Project 17: When Was the Golden Era of Video Games?](https://firdausdimmas.github.io/SQLProject_7/)

* **Objective:** Explore if video games are improving over time or if their "golden age" has passed by analyzing review scores and global sales.
* **Goal:** Uncover the most celebrated eras in gaming history and gain insights into the business dynamics of successful games.
* **Dataset:** Data on video game critic scores, user ratings, and sales for the top 400 games released since 1977.
* **Key Analysis:** Analyzed video game data to determine if games are improving over time, identifying best-selling games and the years with the highest critic and user scores.
* **Tools used:** PostgreSQL (used for storing, managing, and querying the video game sales and review dataset).
* **Outcome:** Top-selling games were mostly from the late 2000s-2010s; 1998, 2002, and 2004 had the highest average critic scores, with 1998 being the top year.

## [Project 18: Analyzing Electric Vehicle Charging Habits](https://firdausdimmas.github.io/SQLProject_8/)

* **Objective:** Analyze electric vehicle (EV) charging usage data to help apartment building managers understand tenant charging habits.
* **Goal:** Provide insights into peak usage times, station availability, and demand patterns for better infrastructure planning and tenant satisfaction.
* **Dataset:** EV charging usage data from Kaggle, loaded into a `charging_sessions` table.
* **Key Analysis:** Analyzed EV charging usage data to understand tenant charging habits, identifying peak usage times, station availability issues, and overall demand patterns.
* **Tools used:** PostgreSQL (used for storing the `charging_sessions` dataset and performing queries for analysis).
* **Outcome:** Garage BI2 had the most unique users; popular charging times were Sundays between 3 p.m. and 7 p.m.; users "Share-9" and "Share-17" had significantly long average charging durations.

## [Project 19: Analyzing Industry Carbon Emissions](https://firdausdimmas.github.io/SQLProject_9/)

* **Objective:** Analyze industry carbon emissions to identify the worst-offending industries in 2017 based on product carbon footprints (PCFs).
* **Goal:** Calculate and compare total carbon footprints across different industry groups using publicly available data.
* **Dataset:** Product carbon footprints (PCFs) data from nature.com, stored in the `product_emissions` table.
* **Key Analysis:** Analyzed industry carbon emissions, specifically identifying the "Materials" industry group as the worst offender in 2017 with a total carbon footprint of 107,129 kgCO2.
* **Tools used:** PostgreSQL (used for storing and querying the `product_emissions` dataset to calculate and compare carbon footprints).
* **Outcome:** The "Materials" industry group had the highest total carbon footprint in 2017, amounting to 107,129 kgCO2.
